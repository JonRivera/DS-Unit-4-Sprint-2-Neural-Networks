{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2mLZuEFWgrY6"
   },
   "source": [
    "<!-- \n",
    "Author: Brian Thomas Ross <ml@brianthomasross.com>\n",
    "License: BSD-3-Clause\n",
    "-->\n",
    "\n",
    "# Neural Network Foundations\n",
    "\n",
    "----\n",
    "\n",
    "This study guide should reinforce and provide practice for all the concepts you have seen in the past week. There are a mix of written question and coding exercises, both are equally important to prepare you for the sprint challenge, as well as being able to comfortably speak on these topics in interviews and on the job.\n",
    "\n",
    "If you get stuck or unsure of something remember the 20 minute rule. If that doesn't help then research a solution with [Google](https://www.google.com/) or [StackOverflow](https://wwww.stackoverflow.com/). Only once you have truly exhausted these methods should you turn to your Team Lead. They wont be there during the sprint challenge or during an interview. That being said, don't hesitate to ask for help if you truly are stuck.\n",
    "\n",
    "Have fun!\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cXdNncKph7PS"
   },
   "source": [
    "## Definitions\n",
    "\n",
    "Use your own words to define the following terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gYfMsaXMiMfm"
   },
   "source": [
    "### Input Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "45ZGRAiwiMdO"
   },
   "source": [
    "Input layer — initial data for the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xnkeavm3iMY5"
   },
   "source": [
    "### Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3XI9_Z4liMWu"
   },
   "source": [
    "Hidden layers — intermediate layer between input and output layer and place where all the computation is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eaQz5joTiMUb"
   },
   "source": [
    "### Output Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "831G2buuiMSA"
   },
   "source": [
    "Output layer — produce the result for given inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://towardsdatascience.com/everything-you-need-to-know-about-neural-networks-and-backpropagation-machine-learning-made-easy-e5285bc2be3a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O4C2zwuxiMD_"
   },
   "source": [
    "### Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_2rY9EE9iMBo"
   },
   "source": [
    "Within an artificial neural network, a neuron is a mathematical function that mimics a biological neuron. Typically, a neuron computes the weighted sum of its input, and this sum is passed through a nonlinear function, often called activation function, such as the sigmoid. \n",
    "https://i.stack.imgur.com/wXL9A.png\n",
    "https://stats.stackexchange.com/questions/241888/what-are-neurons-in-neural-networks-how-do-they-work/241904#:~:text=Within%20an%20artificial%20neural%20network,function%2C%20such%20as%20the%20sigmoid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](wXL9A.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.stack.imgur.com/wXL9A.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L1BpTrJWiL_N"
   },
   "source": [
    "### Weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Weights, on the other hand, can be thought of as the strength of the connection. Weight affects the amount of influence a change in the input will have upon the output. A low weight value will have no change on the input, and alternatively a larger weight value will more significantly change the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KIzxvqcliaBa"
   },
   "source": [
    "### Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k71r029FiZ_N"
   },
   "source": [
    "Simply, bias represents how far off the predictions are from their intended value. Biases make up the difference between the function's output and its intended output. A low bias suggest that the network is making more assumptions about the form of the output, whereas a high bias value makes less assumptions about the form of the output.\n",
    "https://deepai.org/machine-learning-glossary-and-terms/weight-artificial-neural-network#:~:text=Weight%20is%20the%20parameter%20within,weight%2C%20and%20a%20bias%20value.&text=Often%20the%20weights%20of%20a,hidden%20layers%20of%20the%20network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FpW0FPFkiZ-D"
   },
   "source": [
    "### Acitivation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BlpU1Qa8iZ7r"
   },
   "source": [
    "\n",
    "In Neural Network the activation function defines if given node should be “activated” or not based on the weighted sum. Let’s define this weighted sum value as z. In this section I would explain why “Step Function” and “Linear Function” won’t work and talk about “Sigmoid Function” one of the most popular activation functions. There are also other functions which I will leave aside for now.https://towardsdatascience.com/everything-you-need-to-know-about-neural-networks-and-backpropagation-machine-learning-made-easy-e5285bc2be3a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/939/1*uz3wd5YeVYlU2JR8rE9VDA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YQ4H7hu7iZ5N"
   },
   "source": [
    "### Node Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E1UXX7q0iZ26"
   },
   "source": [
    "a map showing the different neurons and then reslatioships betweeeen different nodes based on weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_oK9gvviZ1C"
   },
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XrpGD0GOiZyx"
   },
   "source": [
    "Perceptron is a single layer neural network (not including the inputs) and a multi-layer perceptron is called Neural Networks.; It consists of Input values,\n",
    "Weights and Bias,the Net sum, and an Activation Function.\n",
    "https://towardsdatascience.com/what-the-hell-is-perceptron-626217814f53"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OWyEK7PziZv5"
   },
   "source": [
    "### Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sGelGaRLiZs8"
   },
   "source": [
    "One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE.https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IZcPz7fliZp0"
   },
   "source": [
    "### Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFmCxRVvglrP"
   },
   "source": [
    "They are called feedforward because information only travels forward in the network (no loops), first through the input nodes, then through the hidden nodes (if present), and finally through the output nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8tuJhVJ7ityO"
   },
   "source": [
    "### Back Propogation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "78pvOoJPiuLp"
   },
   "source": [
    "In machine learning, backpropagation (backprop,[1] BP) is a widely used algorithm in training feedforward neural networks for supervised learning. Generalizations of backpropagation exist for other artificial neural networks (ANNs), and for functions generally – a class of algorithms referred to generically as \"backpropagation\".[2] In fitting a neural network, backpropagation computes the gradient of the loss function with respect to the weights of the network for a single input–output example, and does so efficiently, unlike a naive direct computation of the gradient with respect to each weight individually. This efficiency makes it feasible to use gradient methods for training multilayer networks, updating weights to minimize loss;https://en.wikipedia.org/wiki/Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KLErlhhoi3kl"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XwiPqcW_itvZ"
   },
   "source": [
    "## Concepts\n",
    "\n",
    "Answer the following questions using your own words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhtieWU0i6yQ"
   },
   "source": [
    "### Casually explain the steps involved to go from input to output in a simple neural network. How are predictions generated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbIyfH1Hj-aG"
   },
   "source": [
    "As I understand it, we are essentialy pluggin in our our inputs and we create a nerural network that gets train on the data. From there depending on our hyperparameters, batch, optimizer. layers, weights, bias and others the model then is able to output a prediction. Ideally our loss function is low and our accuracy is high, if this is not case then we can always go back to the drawing board. Neuronetworks learn by a  \"feedback process called backpropagation (sometimes abbreviated as \"backprop\"). This involves comparing the output a network produces with the output it was meant to produce, and using the difference between them to modify the weights of the connections between the units in the network, working from the output units through the hidden units to the input units—going backward, in other words. In time, backpropagation causes the network to learn, reducing the difference between actual and intended output to the point where the two exactly coincide, so the network figures things out exactly as it should.\"https://www.explainthatstuff.com/introduction-to-neural-networks.html#:~:text=Information%20flows%20through%20a%20neural,arrive%20at%20the%20output%20units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hh17Eck3j-cV"
   },
   "source": [
    "### What kind of use cases exist for Neural Networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ml3oHS9okKQz"
   },
   "source": [
    "Some cases but not limited include: olving many business problems such as sales forecasting, customer research, data validation, and risk management. For example, at Statsbot we apply neural networks for time-series predictions, anomaly detection in data, and natural language understanding.https://blog.statsbot.co/neural-networks-for-beginners-d99f2235efca ; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Fe_q81EkK49"
   },
   "source": [
    "### How does a neural network address the curse of dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qK6k8RHokLUD"
   },
   "source": [
    "one possible explanation :  high dimensional data there is some underlying pattern in lower level dimensions that deep learning methods are good at exploiting. So given a high dimensional matrix that represents images, neural networks excel at finding low dimensional features that are not apparent in the high dimensional representation. https://hackernoon.com/what-killed-the-curse-of-dimensionality-8dbfad265bbe ;  traditional Machine Learning algorithms will certainly reach a level, where more data doesn’t improve their performance. The chart below illustrates that perfectly:https://www.experfy.com/blog/pros-and-cons-of-neural-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BbSi489UkLj9"
   },
   "source": [
    "### What are some potential pro / cons of using neural netowrks versus more traditional statistical models such as logistic regression or a decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKi9p-AQkLha"
   },
   "source": [
    "https://www.marktechpost.com/2019/04/18/introduction-to-neural-networks-advantages-and-applications/#:~:text=Advantages%20of%20Neural%20Networks%3A,does%20not%20affect%20its%20working.\n",
    "Main Advantages are Neural Networks have the ability to learn by themselves and produce the output that is not limited to the input provided to them.\n",
    "The input is stored in its own networks instead of a database, hence the loss of data does not affect its working.\n",
    "These networks can learn from examples and apply them when a similar event arises, making them able to work through real-time events.\n",
    "Even if a neuron is not responding or a piece of information is missing, the network can detect the fault and still produce the output.\n",
    "They can perform multiple tasks in parallel without affecting the system performance. \n",
    "https://www.experfy.com/blog/pros-and-cons-of-neural-networks/ The probably best-known disadvantage of Neural Networks is their “black box” nature, meaning that you don’t know how and why your NN came up with a certain output. For example, when you put in an image of a cat into a neural network and it predicts it to be a car, it is very hard to understand what caused it to came up with this prediction. When you have features that are human interpretable, it is much easier to understand the cause of its mistake. In Comparison, algorithms like Decision trees are very interpretable. This is important because in some domains, interpretability is quite important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BJRR0afFkLRF"
   },
   "source": [
    "### How would you determine the size of the input layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gErA43eekK2j"
   },
   "source": [
    "Every network has a single input layer and a single output layer. The number of neurons in the input layer equals the number of input variables in the data being processed. The number of neurons in the output layer equals the number of outputs associated with each input. But the challenge is knowing the number of hidden layers and their neurons.https://towardsdatascience.com/beginners-ask-how-many-hidden-layers-neurons-to-use-in-artificial-neural-networks-51466afa0d3e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ryPkPZFhpIWL"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rCqU2sEqpKwl"
   },
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WProsWxgrOgp"
   },
   "source": [
    "This is an open ended challenge using the titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hCS6M0syrPPC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import time\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MYdRpDA-XvO3"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_csv = 'train.csv'\n",
    "test_csv = 'test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_csv, index_col='PassengerId')\n",
    "test_df = pd.read_csv(test_csv, index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Name      891 non-null    object \n",
      " 3   Sex       891 non-null    object \n",
      " 4   Age       714 non-null    float64\n",
      " 5   SibSp     891 non-null    int64  \n",
      " 6   Parch     891 non-null    int64  \n",
      " 7   Ticket    891 non-null    object \n",
      " 8   Fare      891 non-null    float64\n",
      " 9   Cabin     204 non-null    object \n",
      " 10  Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 83.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    418 non-null    int64  \n",
      " 1   Name      418 non-null    object \n",
      " 2   Sex       418 non-null    object \n",
      " 3   Age       332 non-null    float64\n",
      " 4   SibSp     418 non-null    int64  \n",
      " 5   Parch     418 non-null    int64  \n",
      " 6   Ticket    418 non-null    object \n",
      " 7   Fare      417 non-null    float64\n",
      " 8   Cabin     91 non-null     object \n",
      " 9   Embarked  418 non-null    object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 35.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploring data by looking at df.info and df.head()\n",
    "train_df.info(), test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OMYbm2LXYqYk"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create wrangle function\n",
    "def wrangle(df):\n",
    "  df.drop(['Name', 'Ticket', 'Cabin',], axis=1, inplace=True)\n",
    "  df = df.dropna()\n",
    "     \n",
    "   \n",
    "  return df\n",
    "\n",
    "# Wrangle feature matrix\n",
    "X = wrangle(train_df.copy())\n",
    "\n",
    "# Separate labels from feature matrix\n",
    "y = X.pop('Survived')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(             Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       " PassengerId                                                      \n",
       " 1                 3    male  22.0      1      0   7.2500        S\n",
       " 2                 1  female  38.0      1      0  71.2833        C\n",
       " 3                 3  female  26.0      0      0   7.9250        S\n",
       " 4                 1  female  35.0      1      0  53.1000        S\n",
       " 5                 3    male  35.0      0      0   8.0500        S\n",
       " ...             ...     ...   ...    ...    ...      ...      ...\n",
       " 886               3  female  39.0      0      5  29.1250        Q\n",
       " 887               2    male  27.0      0      0  13.0000        S\n",
       " 888               1  female  19.0      0      0  30.0000        S\n",
       " 890               1    male  26.0      0      0  30.0000        C\n",
       " 891               3    male  32.0      0      0   7.7500        Q\n",
       " \n",
       " [712 rows x 7 columns],\n",
       " PassengerId\n",
       " 1      0\n",
       " 2      1\n",
       " 3      1\n",
       " 4      1\n",
       " 5      0\n",
       "       ..\n",
       " 886    0\n",
       " 887    0\n",
       " 888    1\n",
       " 890    1\n",
       " 891    0\n",
       " Name: Survived, Length: 712, dtype: int64)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZ-rthmsY_lh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 7), (143, 7), (569,), (143,))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split and scale the data\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val,y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "#Check shape of train val split\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27.7500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>91.0792</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0458</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.7500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "PassengerId                                                      \n",
       "473               2  female  33.0      1      2  27.7500        S\n",
       "433               2  female  42.0      1      0  26.0000        S\n",
       "667               2    male  25.0      0      0  13.0000        S\n",
       "31                1    male  40.0      0      0  27.7208        C\n",
       "292               1  female  19.0      1      0  91.0792        C\n",
       "...             ...     ...   ...    ...    ...      ...      ...\n",
       "94                3    male  26.0      1      2  20.5750        S\n",
       "136               2    male  23.0      0      0  15.0458        C\n",
       "339               3    male  45.0      0      0   8.0500        S\n",
       "550               2    male   8.0      1      1  36.7500        S\n",
       "132               3    male  20.0      0      0   7.0500        S\n",
       "\n",
       "[569 rows x 7 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 569 entries, 473 to 132\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    569 non-null    int64  \n",
      " 1   Sex       569 non-null    object \n",
      " 2   Age       569 non-null    float64\n",
      " 3   SibSp     569 non-null    int64  \n",
      " 4   Parch     569 non-null    int64  \n",
      " 5   Fare      569 non-null    float64\n",
      " 6   Embarked  569 non-null    object \n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 35.6+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-204-03c36d962c92>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[['Sex','Embarked']] = enc.fit_transform(X_train[['Sex','Embarked']])\n",
      "/Users/johnrivera/.virtualenvs/DS-Unit-4-Sprint-2-Neural-Networks-Hdtrba5g/lib/python3.8/site-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n",
      "<ipython-input-204-03c36d962c92>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[['Sex','Embarked']] = enc.fit_transform(X_val[['Sex','Embarked']])\n",
      "/Users/johnrivera/.virtualenvs/DS-Unit-4-Sprint-2-Neural-Networks-Hdtrba5g/lib/python3.8/site-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "ss = StandardScaler()\n",
    "#encode columns known to have string values using ordinal encoding\n",
    "X_train[['Sex','Embarked']] = enc.fit_transform(X_train[['Sex','Embarked']])\n",
    "X_val[['Sex','Embarked']] = enc.fit_transform(X_val[['Sex','Embarked']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 7), (143, 7))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ss.fit_transform(X_train)\n",
    "X_val = ss.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 7), (143, 7))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    " #helps display tensoryboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 569, 7) for input Tensor(\"dense_57_input:0\", shape=(None, 569, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 569, 7) for input Tensor(\"dense_57_input:0\", shape=(None, 569, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
      " 2/18 [==>...........................] - ETA: 3s - loss: 4.6077 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0132s vs `on_train_batch_end` time: 0.3792s). Check your callbacks.\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 569, 7) for input Tensor(\"dense_57_input:0\", shape=(None, 569, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 4.5703 - accuracy: 0.4042 - val_loss: 4.5272 - val_accuracy: 0.5664\n",
      "Epoch 2/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.4901 - accuracy: 0.6134 - val_loss: 4.4490 - val_accuracy: 0.5734\n",
      "Epoch 3/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.4113 - accuracy: 0.6134 - val_loss: 4.3710 - val_accuracy: 0.5874\n",
      "Epoch 4/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.3339 - accuracy: 0.6362 - val_loss: 4.2960 - val_accuracy: 0.5944\n",
      "Epoch 5/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.2598 - accuracy: 0.6169 - val_loss: 4.2241 - val_accuracy: 0.5664\n",
      "Epoch 6/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.1892 - accuracy: 0.6081 - val_loss: 4.1561 - val_accuracy: 0.5664\n",
      "Epoch 7/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.1224 - accuracy: 0.6063 - val_loss: 4.0913 - val_accuracy: 0.5594\n",
      "Epoch 8/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.0586 - accuracy: 0.6046 - val_loss: 4.0290 - val_accuracy: 0.5594\n",
      "Epoch 9/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.9968 - accuracy: 0.6046 - val_loss: 3.9688 - val_accuracy: 0.5594\n",
      "Epoch 10/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.9372 - accuracy: 0.6046 - val_loss: 3.9099 - val_accuracy: 0.5594\n",
      "Epoch 11/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.8782 - accuracy: 0.6046 - val_loss: 3.8512 - val_accuracy: 0.5594\n",
      "Epoch 12/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.8203 - accuracy: 0.6046 - val_loss: 3.7946 - val_accuracy: 0.5594\n",
      "Epoch 13/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.7628 - accuracy: 0.6046 - val_loss: 3.7371 - val_accuracy: 0.5594\n",
      "Epoch 14/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.7048 - accuracy: 0.6151 - val_loss: 3.6798 - val_accuracy: 0.5594\n",
      "Epoch 15/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.6477 - accuracy: 0.6134 - val_loss: 3.6235 - val_accuracy: 0.5594\n",
      "Epoch 16/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.5923 - accuracy: 0.6046 - val_loss: 3.5694 - val_accuracy: 0.5594\n",
      "Epoch 17/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.5387 - accuracy: 0.6046 - val_loss: 3.5153 - val_accuracy: 0.5594\n",
      "Epoch 18/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.4839 - accuracy: 0.6467 - val_loss: 3.4605 - val_accuracy: 0.6014\n",
      "Epoch 19/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.4296 - accuracy: 0.6995 - val_loss: 3.4069 - val_accuracy: 0.6294\n",
      "Epoch 20/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.3755 - accuracy: 0.7047 - val_loss: 3.3535 - val_accuracy: 0.6434\n",
      "Epoch 21/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.3220 - accuracy: 0.7153 - val_loss: 3.3009 - val_accuracy: 0.6434\n",
      "Epoch 22/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.2691 - accuracy: 0.7188 - val_loss: 3.2485 - val_accuracy: 0.6434\n",
      "Epoch 23/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.2160 - accuracy: 0.7153 - val_loss: 3.1963 - val_accuracy: 0.6364\n",
      "Epoch 24/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.1639 - accuracy: 0.7135 - val_loss: 3.1449 - val_accuracy: 0.6503\n",
      "Epoch 25/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.1121 - accuracy: 0.7188 - val_loss: 3.0937 - val_accuracy: 0.6434\n",
      "Epoch 26/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.0608 - accuracy: 0.7100 - val_loss: 3.0427 - val_accuracy: 0.6294\n",
      "Epoch 27/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.0093 - accuracy: 0.7030 - val_loss: 2.9912 - val_accuracy: 0.6294\n",
      "Epoch 28/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.9573 - accuracy: 0.6907 - val_loss: 2.9395 - val_accuracy: 0.6294\n",
      "Epoch 29/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.9056 - accuracy: 0.6784 - val_loss: 2.8883 - val_accuracy: 0.5944\n",
      "Epoch 30/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.8544 - accuracy: 0.6520 - val_loss: 2.8368 - val_accuracy: 0.5734\n",
      "Epoch 31/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.8022 - accuracy: 0.6116 - val_loss: 2.7837 - val_accuracy: 0.5594\n",
      "Epoch 32/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.7490 - accuracy: 0.6046 - val_loss: 2.7301 - val_accuracy: 0.5594\n",
      "Epoch 33/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6954 - accuracy: 0.6046 - val_loss: 2.6770 - val_accuracy: 0.5594\n",
      "Epoch 34/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.6429 - accuracy: 0.6046 - val_loss: 2.6249 - val_accuracy: 0.5594\n",
      "Epoch 35/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.5908 - accuracy: 0.6046 - val_loss: 2.5729 - val_accuracy: 0.5594\n",
      "Epoch 36/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.5389 - accuracy: 0.6046 - val_loss: 2.5213 - val_accuracy: 0.5594\n",
      "Epoch 37/99\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.4876 - accuracy: 0.6046 - val_loss: 2.4706 - val_accuracy: 0.5594\n",
      "Epoch 38/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.4369 - accuracy: 0.6046 - val_loss: 2.4202 - val_accuracy: 0.5594\n",
      "Epoch 39/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3865 - accuracy: 0.6046 - val_loss: 2.3704 - val_accuracy: 0.5594\n",
      "Epoch 40/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3369 - accuracy: 0.6046 - val_loss: 2.3212 - val_accuracy: 0.5594\n",
      "Epoch 41/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2878 - accuracy: 0.6046 - val_loss: 2.2725 - val_accuracy: 0.5594\n",
      "Epoch 42/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2396 - accuracy: 0.6046 - val_loss: 2.2253 - val_accuracy: 0.5594\n",
      "Epoch 43/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.1923 - accuracy: 0.6046 - val_loss: 2.1785 - val_accuracy: 0.5594\n",
      "Epoch 44/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.1456 - accuracy: 0.6046 - val_loss: 2.1323 - val_accuracy: 0.5594\n",
      "Epoch 45/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.0994 - accuracy: 0.6046 - val_loss: 2.0867 - val_accuracy: 0.5594\n",
      "Epoch 46/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.0538 - accuracy: 0.6046 - val_loss: 2.0417 - val_accuracy: 0.5594\n",
      "Epoch 47/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.0087 - accuracy: 0.6046 - val_loss: 1.9973 - val_accuracy: 0.5594\n",
      "Epoch 48/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.9644 - accuracy: 0.6046 - val_loss: 1.9540 - val_accuracy: 0.5594\n",
      "Epoch 49/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.9221 - accuracy: 0.6046 - val_loss: 1.9129 - val_accuracy: 0.5594\n",
      "Epoch 50/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8810 - accuracy: 0.6046 - val_loss: 1.8724 - val_accuracy: 0.5594\n",
      "Epoch 51/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8406 - accuracy: 0.6046 - val_loss: 1.8326 - val_accuracy: 0.5594\n",
      "Epoch 52/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8010 - accuracy: 0.6046 - val_loss: 1.7936 - val_accuracy: 0.5594\n",
      "Epoch 53/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7620 - accuracy: 0.6046 - val_loss: 1.7553 - val_accuracy: 0.5594\n",
      "Epoch 54/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7239 - accuracy: 0.6046 - val_loss: 1.7178 - val_accuracy: 0.5594\n",
      "Epoch 55/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6866 - accuracy: 0.6046 - val_loss: 1.6812 - val_accuracy: 0.5594\n",
      "Epoch 56/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6502 - accuracy: 0.6046 - val_loss: 1.6455 - val_accuracy: 0.5594\n",
      "Epoch 57/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6146 - accuracy: 0.6046 - val_loss: 1.6106 - val_accuracy: 0.5594\n",
      "Epoch 58/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5800 - accuracy: 0.6046 - val_loss: 1.5768 - val_accuracy: 0.5594\n",
      "Epoch 59/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5464 - accuracy: 0.6046 - val_loss: 1.5439 - val_accuracy: 0.5594\n",
      "Epoch 60/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5136 - accuracy: 0.6046 - val_loss: 1.5119 - val_accuracy: 0.5594\n",
      "Epoch 61/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4819 - accuracy: 0.6046 - val_loss: 1.4809 - val_accuracy: 0.5594\n",
      "Epoch 62/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4512 - accuracy: 0.6046 - val_loss: 1.4509 - val_accuracy: 0.5594\n",
      "Epoch 63/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4215 - accuracy: 0.6046 - val_loss: 1.4220 - val_accuracy: 0.5594\n",
      "Epoch 64/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.3929 - accuracy: 0.6046 - val_loss: 1.3941 - val_accuracy: 0.5594\n",
      "Epoch 65/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.3652 - accuracy: 0.6046 - val_loss: 1.3672 - val_accuracy: 0.5594\n",
      "Epoch 66/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.3385 - accuracy: 0.6046 - val_loss: 1.3412 - val_accuracy: 0.5594\n",
      "Epoch 67/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3128 - accuracy: 0.6046 - val_loss: 1.3162 - val_accuracy: 0.5594\n",
      "Epoch 68/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2880 - accuracy: 0.6046 - val_loss: 1.2921 - val_accuracy: 0.5594\n",
      "Epoch 69/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2642 - accuracy: 0.6046 - val_loss: 1.2690 - val_accuracy: 0.5594\n",
      "Epoch 70/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2413 - accuracy: 0.6046 - val_loss: 1.2469 - val_accuracy: 0.5594\n",
      "Epoch 71/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2195 - accuracy: 0.6046 - val_loss: 1.2258 - val_accuracy: 0.5594\n",
      "Epoch 72/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.1986 - accuracy: 0.6046 - val_loss: 1.2056 - val_accuracy: 0.5594\n",
      "Epoch 73/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1785 - accuracy: 0.6046 - val_loss: 1.1862 - val_accuracy: 0.5594\n",
      "Epoch 74/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1592 - accuracy: 0.6046 - val_loss: 1.1676 - val_accuracy: 0.5594\n",
      "Epoch 75/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1408 - accuracy: 0.6046 - val_loss: 1.1499 - val_accuracy: 0.5594\n",
      "Epoch 76/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1233 - accuracy: 0.6046 - val_loss: 1.1332 - val_accuracy: 0.5594\n",
      "Epoch 77/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1065 - accuracy: 0.6046 - val_loss: 1.1171 - val_accuracy: 0.5594\n",
      "Epoch 78/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0906 - accuracy: 0.6046 - val_loss: 1.1017 - val_accuracy: 0.5594\n",
      "Epoch 79/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0752 - accuracy: 0.6046 - val_loss: 1.0870 - val_accuracy: 0.5594\n",
      "Epoch 80/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0605 - accuracy: 0.6046 - val_loss: 1.0728 - val_accuracy: 0.5594\n",
      "Epoch 81/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0464 - accuracy: 0.6046 - val_loss: 1.0593 - val_accuracy: 0.5594\n",
      "Epoch 82/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0331 - accuracy: 0.6046 - val_loss: 1.0467 - val_accuracy: 0.5594\n",
      "Epoch 83/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0206 - accuracy: 0.6046 - val_loss: 1.0345 - val_accuracy: 0.5594\n",
      "Epoch 84/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0087 - accuracy: 0.6046 - val_loss: 1.0229 - val_accuracy: 0.5594\n",
      "Epoch 85/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9972 - accuracy: 0.6046 - val_loss: 1.0118 - val_accuracy: 0.5594\n",
      "Epoch 86/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9862 - accuracy: 0.6046 - val_loss: 1.0011 - val_accuracy: 0.5594\n",
      "Epoch 87/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9757 - accuracy: 0.6046 - val_loss: 0.9913 - val_accuracy: 0.5594\n",
      "Epoch 88/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9659 - accuracy: 0.6046 - val_loss: 0.9818 - val_accuracy: 0.5594\n",
      "Epoch 89/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9563 - accuracy: 0.6046 - val_loss: 0.9727 - val_accuracy: 0.5594\n",
      "Epoch 90/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9472 - accuracy: 0.6046 - val_loss: 0.9639 - val_accuracy: 0.5594\n",
      "Epoch 91/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9384 - accuracy: 0.6046 - val_loss: 0.9554 - val_accuracy: 0.5594\n",
      "Epoch 92/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9300 - accuracy: 0.6046 - val_loss: 0.9473 - val_accuracy: 0.5594\n",
      "Epoch 93/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9219 - accuracy: 0.6046 - val_loss: 0.9395 - val_accuracy: 0.5594\n",
      "Epoch 94/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9141 - accuracy: 0.6046 - val_loss: 0.9320 - val_accuracy: 0.5594\n",
      "Epoch 95/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9066 - accuracy: 0.6046 - val_loss: 0.9247 - val_accuracy: 0.5594\n",
      "Epoch 96/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8993 - accuracy: 0.6046 - val_loss: 0.9177 - val_accuracy: 0.5594\n",
      "Epoch 97/99\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8924 - accuracy: 0.6046 - val_loss: 0.9111 - val_accuracy: 0.5594\n",
      "Epoch 98/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8857 - accuracy: 0.6046 - val_loss: 0.9046 - val_accuracy: 0.5594\n",
      "Epoch 99/99\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8792 - accuracy: 0.6046 - val_loss: 0.8983 - val_accuracy: 0.5594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x145652be0>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.layers import ReLU\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "logdir = os.path.join(\"logs\", \"EarlyStopping-Loss\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3)\n",
    "\n",
    "def create_model(units=320, activation='relu', learning_rate=.001):\n",
    "    model = tf.keras.Sequential([Dense(units=units,input_shape=(569,7), activation=activation),\n",
    "       Dense(units=150,activation = 'softmax'),\n",
    "       Dense(100, activation ='softmax')])\n",
    "    model.compile(\n",
    "      optimizer= tf.keras.optimizers.Adamax(learning_rate=learning_rate),\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "    return model\n",
    "model = create_model()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=99, \n",
    "          validation_data=(X_val,y_val),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h_GHCzYkaHpr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9de609c477d76535\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9de609c477d76535\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Grid Search to fit and get score of model\n",
    "logdir = os.path.join(\"logs\", \"EarlyStopping-Loss\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 0s 807us/step - loss: 4.2994 - accuracy: 0.6239\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 3.6907 - accuracy: 0.6837\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 3.1346 - accuracy: 0.6450\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 2.6237 - accuracy: 0.6977\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 885us/step - loss: 2.1697 - accuracy: 0.7715\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 885us/step - loss: 1.7841 - accuracy: 0.7944\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 843us/step - loss: 1.4755 - accuracy: 0.7909\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 809us/step - loss: 1.2329 - accuracy: 0.7996\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 699us/step - loss: 1.0483 - accuracy: 0.7961\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 835us/step - loss: 0.9047 - accuracy: 0.8032\n",
      "Best: 0.6957684755325317 using {'activation': 'relu', 'epochs': 10, 'learning_rate': 0.01, 'units': 20}\n",
      "Means: 0.6045404076576233, Stdev: 0.01651221513748169 with: {'activation': 'relu', 'epochs': 5, 'learning_rate': 0.01, 'units': 10}\n",
      "Means: 0.6238386631011963, Stdev: 0.03581047058105469 with: {'activation': 'relu', 'epochs': 5, 'learning_rate': 0.01, 'units': 20}\n",
      "Means: 0.6466456651687622, Stdev: 0.058617472648620605 with: {'activation': 'relu', 'epochs': 5, 'learning_rate': 0.001, 'units': 10}\n",
      "Means: 0.6589263677597046, Stdev: 0.07089817523956299 with: {'activation': 'relu', 'epochs': 5, 'learning_rate': 0.001, 'units': 20}\n",
      "Means: 0.6080491840839386, Stdev: 0.020020991563796997 with: {'activation': 'relu', 'epochs': 10, 'learning_rate': 0.01, 'units': 10}\n",
      "Means: 0.6957684755325317, Stdev: 0.10774028301239014 with: {'activation': 'relu', 'epochs': 10, 'learning_rate': 0.01, 'units': 20}\n",
      "Means: 0.6115702986717224, Stdev: 0.016499876976013184 with: {'activation': 'relu', 'epochs': 10, 'learning_rate': 0.001, 'units': 10}\n",
      "Means: 0.6045404076576233, Stdev: 0.01651221513748169 with: {'activation': 'relu', 'epochs': 10, 'learning_rate': 0.001, 'units': 20}\n",
      "Means: 0.6045404076576233, Stdev: 0.01651221513748169 with: {'activation': 'sigmoid', 'epochs': 5, 'learning_rate': 0.01, 'units': 10}\n",
      "Means: 0.6045404076576233, Stdev: 0.01651221513748169 with: {'activation': 'sigmoid', 'epochs': 5, 'learning_rate': 0.01, 'units': 20}\n",
      "Means: 0.6045404076576233, Stdev: 0.01651221513748169 with: {'activation': 'sigmoid', 'epochs': 5, 'learning_rate': 0.001, 'units': 10}\n",
      "Means: 0.6045404076576233, Stdev: 0.01651221513748169 with: {'activation': 'sigmoid', 'epochs': 5, 'learning_rate': 0.001, 'units': 20}\n",
      "Means: 0.6045404076576233, Stdev: 0.01651221513748169 with: {'activation': 'sigmoid', 'epochs': 10, 'learning_rate': 0.01, 'units': 10}\n",
      "Means: 0.6045404076576233, Stdev: 0.01651221513748169 with: {'activation': 'sigmoid', 'epochs': 10, 'learning_rate': 0.01, 'units': 20}\n",
      "Means: 0.6045404076576233, Stdev: 0.01651221513748169 with: {'activation': 'sigmoid', 'epochs': 10, 'learning_rate': 0.001, 'units': 10}\n",
      "Means: 0.6045404076576233, Stdev: 0.01651221513748169 with: {'activation': 'sigmoid', 'epochs': 10, 'learning_rate': 0.001, 'units': 20}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'learning_rate':[.01,.001],\n",
    "              'units': [10,20],\n",
    "              'activation':['relu','sigmoid'],\n",
    "              'epochs': [5,10],\n",
    "              # paramswrapper --we use scikit learn conforms the model scikit learn api\n",
    "              }\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1,cv=2)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LSDS-Unit-4-Sprint-2-Study-Guide.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
