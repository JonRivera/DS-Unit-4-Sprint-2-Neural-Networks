{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Train Practice\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 4* Jonatan Rivera\n",
    "\n",
    "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Apply regularization techniques to your model. \n",
    "\n",
    "*Don't forgot to switch to GPU on Colab!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptJ2b3wk62Ud"
   },
   "source": [
    "## Regularization\n",
    "\n",
    "Using your best performing model from the previous module, apply each of the following regularization strategies: \n",
    "* Early Stopping\n",
    "* Dropout\n",
    "* Weight Decay\n",
    "* Weight Constraint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USXjs7Hk71Hy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#import train_test_split to create training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "def load_quickdraw10(path):\n",
    "    \"\"\" Function returns train and testing matrices w/ corresponding target vectors  for given data\n",
    "    returns X_train,X_test, y_train,  y_test\"\"\"\n",
    "    path = np.load('quickdraw10.npz')\n",
    "    data = path\n",
    "    X = data['arr_0']\n",
    "    y = data['arr_1']\n",
    "    X, y = shuffle(X, y)\n",
    "    \n",
    "    return train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = load_quickdraw10('quickdraw10.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80000, 784), (80000,), (20000, 784), (20000,))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy and pandas libararies incase we need to modify data in pandas data frame\n",
    "import numpy\n",
    "import pandas as pd\n",
    "#Help with hyperparameter tunning\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "#Import model required to build model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best hyperparameters based on last module\n",
    "# units 15.000 ; learning rate 0.0010000 ; optimizer adamax; activation function softmax; kernel initializer random_uniform, bias init ones #had accuracy of 63%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2094/2094 [==============================] - 1s 652us/step - loss: 1.9224 - accuracy: 0.3622\n",
      "Epoch 2/5\n",
      "2094/2094 [==============================] - 1s 602us/step - loss: 1.5284 - accuracy: 0.4556\n",
      "Epoch 3/5\n",
      "2094/2094 [==============================] - 1s 597us/step - loss: 1.3870 - accuracy: 0.4771\n",
      "Epoch 4/5\n",
      "2094/2094 [==============================] - 1s 593us/step - loss: 1.3058 - accuracy: 0.5081\n",
      "Epoch 5/5\n",
      "2094/2094 [==============================] - 1s 602us/step - loss: 1.2404 - accuracy: 0.5356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1476c5520>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct model \n",
    "model = tf.keras.Sequential(\n",
    "    \n",
    "      [Dense(32, activation='relu', input_dim=784),\n",
    "       Dense(units=15,activation = 'softmax',kernel_initializer = 'random_uniform',bias_initializer = 'ones'),\n",
    "       Dense(10, activation ='softmax')])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "      optimizer= tf.keras.optimizers.Adamax(learning_rate=0.001),\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['accuracy']\n",
    "  )\n",
    "#train model and test it  \n",
    "model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Early Stopping Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "   1/2094 [..............................] - ETA: 0s - loss: 4.6063 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0034s vs `on_train_batch_end` time: 0.0426s). Check your callbacks.\n",
      "2094/2094 [==============================] - 5s 2ms/step - loss: 2.9592 - accuracy: 0.2754 - val_loss: 2.1197 - val_accuracy: 0.3012\n",
      "Epoch 2/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 1.9039 - accuracy: 0.2966 - val_loss: 1.7790 - val_accuracy: 0.2985\n",
      "Epoch 3/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 1.7209 - accuracy: 0.3094 - val_loss: 1.6870 - val_accuracy: 0.3119\n",
      "Epoch 4/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 1.6406 - accuracy: 0.3234 - val_loss: 1.6169 - val_accuracy: 0.3212\n",
      "Epoch 5/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 1.5697 - accuracy: 0.3469 - val_loss: 1.5502 - val_accuracy: 0.3546\n",
      "Epoch 6/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 1.5108 - accuracy: 0.3804 - val_loss: 1.5015 - val_accuracy: 0.4049\n",
      "Epoch 7/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 1.4647 - accuracy: 0.4169 - val_loss: 1.4623 - val_accuracy: 0.4547\n",
      "Epoch 8/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 1.4211 - accuracy: 0.4703 - val_loss: 1.4170 - val_accuracy: 0.4987\n",
      "Epoch 9/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 1.3691 - accuracy: 0.5361 - val_loss: 1.3651 - val_accuracy: 0.5725\n",
      "Epoch 10/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 1.3093 - accuracy: 0.5943 - val_loss: 1.3060 - val_accuracy: 0.5963\n",
      "Epoch 11/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 1.2514 - accuracy: 0.6209 - val_loss: 1.2570 - val_accuracy: 0.6271\n",
      "Epoch 12/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 1.1949 - accuracy: 0.6537 - val_loss: 1.1995 - val_accuracy: 0.6948\n",
      "Epoch 13/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 1.1179 - accuracy: 0.7049 - val_loss: 1.1247 - val_accuracy: 0.6995\n",
      "Epoch 14/99\n",
      "2094/2094 [==============================] - 6s 3ms/step - loss: 1.0437 - accuracy: 0.7230 - val_loss: 1.0682 - val_accuracy: 0.6978\n",
      "Epoch 15/99\n",
      "2094/2094 [==============================] - 6s 3ms/step - loss: 0.9845 - accuracy: 0.7404 - val_loss: 1.0232 - val_accuracy: 0.7137\n",
      "Epoch 16/99\n",
      "2094/2094 [==============================] - 8s 4ms/step - loss: 0.9360 - accuracy: 0.7540 - val_loss: 0.9879 - val_accuracy: 0.7292\n",
      "Epoch 17/99\n",
      "2094/2094 [==============================] - 8s 4ms/step - loss: 0.8951 - accuracy: 0.7680 - val_loss: 0.9658 - val_accuracy: 0.7316\n",
      "Epoch 18/99\n",
      "2094/2094 [==============================] - 7s 4ms/step - loss: 0.8590 - accuracy: 0.7819 - val_loss: 0.9376 - val_accuracy: 0.7434\n",
      "Epoch 19/99\n",
      "2094/2094 [==============================] - 7s 3ms/step - loss: 0.8250 - accuracy: 0.7965 - val_loss: 0.9138 - val_accuracy: 0.7564\n",
      "Epoch 20/99\n",
      "2094/2094 [==============================] - 7s 3ms/step - loss: 0.7945 - accuracy: 0.8078 - val_loss: 0.9031 - val_accuracy: 0.7429\n",
      "Epoch 21/99\n",
      "2094/2094 [==============================] - 7s 3ms/step - loss: 0.7657 - accuracy: 0.8203 - val_loss: 0.8835 - val_accuracy: 0.7601\n",
      "Epoch 22/99\n",
      "2094/2094 [==============================] - 6s 3ms/step - loss: 0.7387 - accuracy: 0.8288 - val_loss: 0.8621 - val_accuracy: 0.7752\n",
      "Epoch 23/99\n",
      "2094/2094 [==============================] - 6s 3ms/step - loss: 0.7129 - accuracy: 0.8398 - val_loss: 0.8482 - val_accuracy: 0.7799\n",
      "Epoch 24/99\n",
      "2094/2094 [==============================] - 6s 3ms/step - loss: 0.6883 - accuracy: 0.8489 - val_loss: 0.8417 - val_accuracy: 0.7798\n",
      "Epoch 25/99\n",
      "2094/2094 [==============================] - 5s 3ms/step - loss: 0.6660 - accuracy: 0.8564 - val_loss: 0.8292 - val_accuracy: 0.7785\n",
      "Epoch 26/99\n",
      "2094/2094 [==============================] - 6s 3ms/step - loss: 0.6444 - accuracy: 0.8638 - val_loss: 0.8185 - val_accuracy: 0.7869\n",
      "Epoch 27/99\n",
      "2094/2094 [==============================] - 6s 3ms/step - loss: 0.6232 - accuracy: 0.8721 - val_loss: 0.8156 - val_accuracy: 0.7868\n",
      "Epoch 28/99\n",
      "2094/2094 [==============================] - 5s 3ms/step - loss: 0.6039 - accuracy: 0.8786 - val_loss: 0.8069 - val_accuracy: 0.7886\n",
      "Epoch 29/99\n",
      "2094/2094 [==============================] - 5s 3ms/step - loss: 0.5856 - accuracy: 0.8822 - val_loss: 0.8003 - val_accuracy: 0.7945\n",
      "Epoch 30/99\n",
      "2094/2094 [==============================] - 5s 2ms/step - loss: 0.5663 - accuracy: 0.8893 - val_loss: 0.7905 - val_accuracy: 0.7962\n",
      "Epoch 31/99\n",
      "2094/2094 [==============================] - 6s 3ms/step - loss: 0.5496 - accuracy: 0.8939 - val_loss: 0.7865 - val_accuracy: 0.7943\n",
      "Epoch 32/99\n",
      "2094/2094 [==============================] - 6s 3ms/step - loss: 0.5279 - accuracy: 0.9012 - val_loss: 0.7761 - val_accuracy: 0.7994\n",
      "Epoch 33/99\n",
      "2094/2094 [==============================] - 5s 3ms/step - loss: 0.5035 - accuracy: 0.9068 - val_loss: 0.7549 - val_accuracy: 0.8070\n",
      "Epoch 34/99\n",
      "2094/2094 [==============================] - 5s 3ms/step - loss: 0.4687 - accuracy: 0.9122 - val_loss: 0.7367 - val_accuracy: 0.8137\n",
      "Epoch 35/99\n",
      "2094/2094 [==============================] - 5s 3ms/step - loss: 0.4346 - accuracy: 0.9158 - val_loss: 0.7125 - val_accuracy: 0.8201\n",
      "Epoch 36/99\n",
      "2094/2094 [==============================] - 6s 3ms/step - loss: 0.4062 - accuracy: 0.9198 - val_loss: 0.6925 - val_accuracy: 0.8219\n",
      "Epoch 37/99\n",
      "2094/2094 [==============================] - 6s 3ms/step - loss: 0.3851 - accuracy: 0.9241 - val_loss: 0.6860 - val_accuracy: 0.8234\n",
      "Epoch 38/99\n",
      "2094/2094 [==============================] - 5s 3ms/step - loss: 0.3664 - accuracy: 0.9279 - val_loss: 0.7045 - val_accuracy: 0.8158\n",
      "Epoch 39/99\n",
      "2094/2094 [==============================] - 6s 3ms/step - loss: 0.3510 - accuracy: 0.9314 - val_loss: 0.6909 - val_accuracy: 0.8200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x147440c10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.layers import ReLU\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "logdir = os.path.join(\"logs\", \"EarlyStopping-Loss\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3)\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    \n",
    "      [Dense(320, activation='relu', input_dim=784),\n",
    "       Dense(units=150,activation = 'softmax',kernel_initializer = 'random_uniform',bias_initializer = 'ones'),\n",
    "       Dense(100, activation ='softmax')])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "      optimizer= tf.keras.optimizers.Adamax(learning_rate=0.001),\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=99, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Weight Decay Technique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "   2/2500 [..............................] - ETA: 1:09 - loss: 22.3723 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0073s vs `on_train_batch_end` time: 0.0481s). Check your callbacks.\n",
      "2500/2500 [==============================] - 14s 6ms/step - loss: 4.6616 - accuracy: 0.1077 - val_loss: 2.9412 - val_accuracy: 0.0964\n",
      "Epoch 2/99\n",
      "2500/2500 [==============================] - 17s 7ms/step - loss: 2.5818 - accuracy: 0.0985 - val_loss: 2.4158 - val_accuracy: 0.0975\n",
      "Epoch 3/99\n",
      "2500/2500 [==============================] - 20s 8ms/step - loss: 2.3466 - accuracy: 0.1477 - val_loss: 2.2344 - val_accuracy: 0.1938\n",
      "Epoch 4/99\n",
      "2500/2500 [==============================] - 21s 8ms/step - loss: 2.1594 - accuracy: 0.1954 - val_loss: 2.0987 - val_accuracy: 0.1966\n",
      "Epoch 5/99\n",
      "2500/2500 [==============================] - 17s 7ms/step - loss: 2.0838 - accuracy: 0.1977 - val_loss: 2.0670 - val_accuracy: 0.1973\n",
      "Epoch 6/99\n",
      "2500/2500 [==============================] - 16s 6ms/step - loss: 2.0648 - accuracy: 0.1987 - val_loss: 2.0639 - val_accuracy: 0.1951\n",
      "Epoch 7/99\n",
      "2500/2500 [==============================] - 18s 7ms/step - loss: 2.0587 - accuracy: 0.1982 - val_loss: 2.0584 - val_accuracy: 0.1959\n",
      "Epoch 8/99\n",
      "2500/2500 [==============================] - 21s 8ms/step - loss: 2.0538 - accuracy: 0.1984 - val_loss: 2.0565 - val_accuracy: 0.1962\n",
      "Epoch 9/99\n",
      "2500/2500 [==============================] - 23s 9ms/step - loss: 2.0520 - accuracy: 0.1986 - val_loss: 2.0559 - val_accuracy: 0.1937\n",
      "Epoch 10/99\n",
      "2500/2500 [==============================] - 28s 11ms/step - loss: 2.0511 - accuracy: 0.1999 - val_loss: 2.0574 - val_accuracy: 0.1949\n",
      "Epoch 11/99\n",
      "2500/2500 [==============================] - 23s 9ms/step - loss: 2.0494 - accuracy: 0.2003 - val_loss: 2.0557 - val_accuracy: 0.1945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14a3324f0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "logdir = os.path.join(\"logs\", \"EarlyStopping+L2_WeightDecay\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    \n",
    "      [Dense(512, activation='relu', input_dim=784,kernel_regularizer=regularizers.l2(0.01) ),\n",
    "       ReLU(negative_slope=.01),\n",
    "       Dense(units=512,activation = 'softmax', kernel_regularizer=regularizers.l2(0.01)),\n",
    "       ReLU(negative_slope=.01),\n",
    "       Dense(512,kernel_regularizer=regularizers.l2(0.01), activation ='softmax')])\n",
    "\n",
    "\n",
    "\n",
    "model.compile(\n",
    "      optimizer= tf.keras.optimizers.Adamax(learning_rate=0.001),\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=99, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "re_lu_12 (ReLU)              (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 512)               262656    \n",
      "=================================================================\n",
      "Total params: 927,232\n",
      "Trainable params: 927,232\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e51efaebf4818268\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e51efaebf4818268\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "   2/2500 [..............................] - ETA: 1:25 - loss: 4.6122 - accuracy: 0.0156  WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0041s vs `on_train_batch_end` time: 0.0643s). Check your callbacks.\n",
      "2500/2500 [==============================] - 10s 4ms/step - loss: 2.7336 - accuracy: 0.2132 - val_loss: 2.0452 - val_accuracy: 0.2544\n",
      "Epoch 2/99\n",
      "2500/2500 [==============================] - 10s 4ms/step - loss: 1.9706 - accuracy: 0.2487 - val_loss: 2.0956 - val_accuracy: 0.1902\n",
      "Epoch 3/99\n",
      "2500/2500 [==============================] - 10s 4ms/step - loss: 1.8425 - accuracy: 0.2656 - val_loss: 1.9536 - val_accuracy: 0.2508\n",
      "Epoch 4/99\n",
      "2500/2500 [==============================] - 10s 4ms/step - loss: 1.8018 - accuracy: 0.2710 - val_loss: 1.7503 - val_accuracy: 0.2779\n",
      "Epoch 5/99\n",
      "2500/2500 [==============================] - 10s 4ms/step - loss: 1.7509 - accuracy: 0.2771 - val_loss: 1.7336 - val_accuracy: 0.2730\n",
      "Epoch 6/99\n",
      "2500/2500 [==============================] - 10s 4ms/step - loss: 1.7305 - accuracy: 0.2864 - val_loss: 1.7104 - val_accuracy: 0.2868\n",
      "Epoch 7/99\n",
      "2500/2500 [==============================] - 12s 5ms/step - loss: 1.7519 - accuracy: 0.2776 - val_loss: 1.6934 - val_accuracy: 0.3003\n",
      "Epoch 8/99\n",
      "2500/2500 [==============================] - 17s 7ms/step - loss: 1.6765 - accuracy: 0.3067 - val_loss: 1.6668 - val_accuracy: 0.3157\n",
      "Epoch 9/99\n",
      "2500/2500 [==============================] - 18s 7ms/step - loss: 1.6739 - accuracy: 0.3186 - val_loss: 1.7337 - val_accuracy: 0.3174\n",
      "Epoch 10/99\n",
      "2500/2500 [==============================] - 18s 7ms/step - loss: 1.6766 - accuracy: 0.3135 - val_loss: 1.6264 - val_accuracy: 0.3237\n",
      "Epoch 11/99\n",
      "2500/2500 [==============================] - 17s 7ms/step - loss: 1.6555 - accuracy: 0.3233 - val_loss: 1.6379 - val_accuracy: 0.3215\n",
      "Epoch 12/99\n",
      "2500/2500 [==============================] - 15s 6ms/step - loss: 1.6477 - accuracy: 0.3252 - val_loss: 1.6048 - val_accuracy: 0.3413\n",
      "Epoch 13/99\n",
      "2500/2500 [==============================] - 13s 5ms/step - loss: 1.6560 - accuracy: 0.3325 - val_loss: 1.6036 - val_accuracy: 0.3399\n",
      "Epoch 14/99\n",
      "2500/2500 [==============================] - 13s 5ms/step - loss: 1.6328 - accuracy: 0.3371 - val_loss: 1.6954 - val_accuracy: 0.3266\n",
      "Epoch 15/99\n",
      "2500/2500 [==============================] - 14s 5ms/step - loss: 1.6629 - accuracy: 0.3322 - val_loss: 1.6953 - val_accuracy: 0.3167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x149c773d0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "wc = MaxNorm(max_value=2)\n",
    "\n",
    "logdir = os.path.join(\"logs\", \"EarlyStopping+WeightConstraint+Dropout\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3)\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    \n",
    "      [Dense(320, activation='relu', input_dim=784),\n",
    "       Dense(units=150,activation = 'softmax',kernel_initializer = 'random_uniform',bias_initializer = 'ones'),\n",
    "       Dense(100, activation ='softmax')])\n",
    "\n",
    "model.compile(\n",
    "      optimizer= tf.keras.optimizers.Adamax(learning_rate=0.001),\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=99, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 15324), started 0:45:53 ago. (Use '!kill 15324' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-81f151ecc8ab5a83\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-81f151ecc8ab5a83\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pScpa3nRRxCN"
   },
   "source": [
    "# Deploy\n",
    "\n",
    "Save your model's weights using the Checkpoint function. Try reloading the model and making inference on your validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "2493/2500 [============================>.] - ETA: 0s - loss: 2.8940 - accuracy: 0.3263\n",
      "Epoch 00001: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 2.8916 - accuracy: 0.3263 - val_loss: 2.0195 - val_accuracy: 0.3535\n",
      "Epoch 2/99\n",
      "2490/2500 [============================>.] - ETA: 0s - loss: 1.8286 - accuracy: 0.3487\n",
      "Epoch 00002: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.8284 - accuracy: 0.3487 - val_loss: 1.7065 - val_accuracy: 0.3540\n",
      "Epoch 3/99\n",
      "2470/2500 [============================>.] - ETA: 0s - loss: 1.6526 - accuracy: 0.3567\n",
      "Epoch 00003: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6523 - accuracy: 0.3568 - val_loss: 1.6393 - val_accuracy: 0.3491\n",
      "Epoch 4/99\n",
      "2479/2500 [============================>.] - ETA: 0s - loss: 1.5888 - accuracy: 0.3598\n",
      "Epoch 00004: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5887 - accuracy: 0.3595 - val_loss: 1.5569 - val_accuracy: 0.3602\n",
      "Epoch 5/99\n",
      "2485/2500 [============================>.] - ETA: 0s - loss: 1.5498 - accuracy: 0.3617\n",
      "Epoch 00005: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5490 - accuracy: 0.3619 - val_loss: 1.5483 - val_accuracy: 0.3489\n",
      "Epoch 6/99\n",
      "2474/2500 [============================>.] - ETA: 0s - loss: 1.5158 - accuracy: 0.3612 ETA: 0s - loss: 1.517\n",
      "Epoch 00006: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5153 - accuracy: 0.3614 - val_loss: 1.5019 - val_accuracy: 0.3607\n",
      "Epoch 7/99\n",
      "2488/2500 [============================>.] - ETA: 0s - loss: 1.4936 - accuracy: 0.3681\n",
      "Epoch 00007: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.4936 - accuracy: 0.3681 - val_loss: 1.4817 - val_accuracy: 0.3647\n",
      "Epoch 8/99\n",
      "2483/2500 [============================>.] - ETA: 0s - loss: 1.4703 - accuracy: 0.3704\n",
      "Epoch 00008: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 1.4697 - accuracy: 0.3707 - val_loss: 1.4851 - val_accuracy: 0.3688\n",
      "Epoch 9/99\n",
      "2486/2500 [============================>.] - ETA: 0s - loss: 1.4404 - accuracy: 0.3762\n",
      "Epoch 00009: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.4403 - accuracy: 0.3762 - val_loss: 1.4343 - val_accuracy: 0.3819\n",
      "Epoch 10/99\n",
      "2494/2500 [============================>.] - ETA: 0s - loss: 1.4323 - accuracy: 0.3762\n",
      "Epoch 00010: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 1.4326 - accuracy: 0.3761 - val_loss: 1.4213 - val_accuracy: 0.3731\n",
      "Epoch 11/99\n",
      "2484/2500 [============================>.] - ETA: 0s - loss: 1.4167 - accuracy: 0.3787\n",
      "Epoch 00011: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 10s 4ms/step - loss: 1.4168 - accuracy: 0.3790 - val_loss: 1.4106 - val_accuracy: 0.3787\n",
      "Epoch 12/99\n",
      "2493/2500 [============================>.] - ETA: 0s - loss: 1.4047 - accuracy: 0.3863\n",
      "Epoch 00012: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 10s 4ms/step - loss: 1.4047 - accuracy: 0.3863 - val_loss: 1.4066 - val_accuracy: 0.3837\n",
      "Epoch 13/99\n",
      "2486/2500 [============================>.] - ETA: 0s - loss: 1.3932 - accuracy: 0.3956\n",
      "Epoch 00013: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 1.3929 - accuracy: 0.3958 - val_loss: 1.3957 - val_accuracy: 0.3945\n",
      "Epoch 14/99\n",
      "2494/2500 [============================>.] - ETA: 0s - loss: 1.3832 - accuracy: 0.4035\n",
      "Epoch 00014: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 1.3831 - accuracy: 0.4035 - val_loss: 1.4028 - val_accuracy: 0.4166\n",
      "Epoch 15/99\n",
      "2488/2500 [============================>.] - ETA: 0s - loss: 1.3425 - accuracy: 0.4439\n",
      "Epoch 00015: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.3422 - accuracy: 0.4440 - val_loss: 1.3191 - val_accuracy: 0.4613\n",
      "Epoch 16/99\n",
      "2486/2500 [============================>.] - ETA: 0s - loss: 1.2711 - accuracy: 0.4715\n",
      "Epoch 00016: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.2712 - accuracy: 0.4716 - val_loss: 1.2632 - val_accuracy: 0.4735\n",
      "Epoch 17/99\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 1.2419 - accuracy: 0.4917\n",
      "Epoch 00017: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 1.2418 - accuracy: 0.4917 - val_loss: 1.2355 - val_accuracy: 0.4993\n",
      "Epoch 18/99\n",
      "2496/2500 [============================>.] - ETA: 0s - loss: 1.2226 - accuracy: 0.4950\n",
      "Epoch 00018: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.2223 - accuracy: 0.4951 - val_loss: 1.2421 - val_accuracy: 0.5001\n",
      "Epoch 19/99\n",
      "2489/2500 [============================>.] - ETA: 0s - loss: 1.2097 - accuracy: 0.5010\n",
      "Epoch 00019: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.2096 - accuracy: 0.5009 - val_loss: 1.2210 - val_accuracy: 0.4908\n",
      "Epoch 20/99\n",
      "2479/2500 [============================>.] - ETA: 0s - loss: 1.1943 - accuracy: 0.5070\n",
      "Epoch 00020: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1939 - accuracy: 0.5073 - val_loss: 1.2142 - val_accuracy: 0.5100\n",
      "Epoch 21/99\n",
      "2474/2500 [============================>.] - ETA: 0s - loss: 1.1795 - accuracy: 0.5129\n",
      "Epoch 00021: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1794 - accuracy: 0.5130 - val_loss: 1.2033 - val_accuracy: 0.5064\n",
      "Epoch 22/99\n",
      "2481/2500 [============================>.] - ETA: 0s - loss: 1.1688 - accuracy: 0.5137\n",
      "Epoch 00022: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1692 - accuracy: 0.5136 - val_loss: 1.1992 - val_accuracy: 0.5063\n",
      "Epoch 23/99\n",
      "2478/2500 [============================>.] - ETA: 0s - loss: 1.1397 - accuracy: 0.5170\n",
      "Epoch 00023: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1392 - accuracy: 0.5172 - val_loss: 1.1591 - val_accuracy: 0.5230\n",
      "Epoch 24/99\n",
      "2492/2500 [============================>.] - ETA: 0s - loss: 1.1110 - accuracy: 0.5331\n",
      "Epoch 00024: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1109 - accuracy: 0.5331 - val_loss: 1.1351 - val_accuracy: 0.5309\n",
      "Epoch 25/99\n",
      "2492/2500 [============================>.] - ETA: 0s - loss: 1.0921 - accuracy: 0.5521\n",
      "Epoch 00025: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0923 - accuracy: 0.5521 - val_loss: 1.1085 - val_accuracy: 0.5628\n",
      "Epoch 26/99\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 1.0483 - accuracy: 0.5802\n",
      "Epoch 00026: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0483 - accuracy: 0.5802 - val_loss: 1.0607 - val_accuracy: 0.5815\n",
      "Epoch 27/99\n",
      "2485/2500 [============================>.] - ETA: 0s - loss: 1.0116 - accuracy: 0.5949\n",
      "Epoch 00027: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0113 - accuracy: 0.5951 - val_loss: 1.0220 - val_accuracy: 0.6039\n",
      "Epoch 28/99\n",
      "2480/2500 [============================>.] - ETA: 0s - loss: 0.9868 - accuracy: 0.6048\n",
      "Epoch 00028: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9871 - accuracy: 0.6049 - val_loss: 1.0099 - val_accuracy: 0.6134\n",
      "Epoch 29/99\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 0.9630 - accuracy: 0.6140\n",
      "Epoch 00029: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9631 - accuracy: 0.6139 - val_loss: 0.9962 - val_accuracy: 0.6143\n",
      "Epoch 30/99\n",
      "2483/2500 [============================>.] - ETA: 0s - loss: 0.9363 - accuracy: 0.6225\n",
      "Epoch 00030: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9365 - accuracy: 0.6223 - val_loss: 0.9679 - val_accuracy: 0.6187\n",
      "Epoch 31/99\n",
      "2496/2500 [============================>.] - ETA: 0s - loss: 0.9221 - accuracy: 0.6218\n",
      "Epoch 00031: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9225 - accuracy: 0.6216 - val_loss: 0.9482 - val_accuracy: 0.6173\n",
      "Epoch 32/99\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 0.9074 - accuracy: 0.6244\n",
      "Epoch 00032: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9074 - accuracy: 0.6244 - val_loss: 0.9449 - val_accuracy: 0.6253\n",
      "Epoch 33/99\n",
      "2481/2500 [============================>.] - ETA: 0s - loss: 0.9007 - accuracy: 0.6245\n",
      "Epoch 00033: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9005 - accuracy: 0.6248 - val_loss: 0.9403 - val_accuracy: 0.6301\n",
      "Epoch 34/99\n",
      "2479/2500 [============================>.] - ETA: 0s - loss: 0.8928 - accuracy: 0.6299\n",
      "Epoch 00034: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8931 - accuracy: 0.6298 - val_loss: 0.9392 - val_accuracy: 0.6300\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3)\n",
    "cpoint = tf.keras.callbacks.ModelCheckpoint(\"weights_best.h5\",\n",
    "                                            verbose=1, \n",
    "                                            save_weights_only=True)\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        Dense(320, activation='relu', input_dim=784),\n",
    "        Dense(units=150,activation = 'softmax',kernel_initializer = 'random_uniform',bias_initializer = 'ones'),\n",
    "        Dense(100, activation ='softmax')])\n",
    "  \n",
    "\n",
    "    model.compile(\n",
    "      optimizer= tf.keras.optimizers.Adamax(learning_rate=0.001),\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=99, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[cpoint, stop])\n",
    "    \n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\n",
      "Epoch 00001: saving model to weights_best.h5\n",
      "2500/2500 - 4s - loss: 0.8888 - accuracy: 0.6315 - val_loss: 0.9249 - val_accuracy: 0.6319\n",
      "Epoch 2/2\n",
      "\n",
      "Epoch 00002: saving model to weights_best.h5\n",
      "2500/2500 - 4s - loss: 0.8763 - accuracy: 0.6333 - val_loss: 0.9266 - val_accuracy: 0.6273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14a562d60>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=2, \n",
    "          validation_data=(X_test,y_test),\n",
    "          verbose=2,\n",
    "          callbacks=[cpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 878us/step - loss: 0.9266 - accuracy: 0.6273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9265751838684082, 0.6273000240325928]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Exported Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "2490/2500 [============================>.] - ETA: 0s - loss: 2.8439 - accuracy: 0.2732\n",
      "Epoch 00001: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 2.8405 - accuracy: 0.2731 - val_loss: 1.9791 - val_accuracy: 0.2843\n",
      "Epoch 2/99\n",
      "2483/2500 [============================>.] - ETA: 0s - loss: 1.8144 - accuracy: 0.2851\n",
      "Epoch 00002: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.8139 - accuracy: 0.2850 - val_loss: 1.7640 - val_accuracy: 0.2840\n",
      "Epoch 3/99\n",
      "2480/2500 [============================>.] - ETA: 0s - loss: 1.7023 - accuracy: 0.2880\n",
      "Epoch 00003: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.7020 - accuracy: 0.2879 - val_loss: 1.7430 - val_accuracy: 0.2823\n",
      "Epoch 4/99\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 1.6706 - accuracy: 0.2874\n",
      "Epoch 00004: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6706 - accuracy: 0.2874 - val_loss: 1.6744 - val_accuracy: 0.2794\n",
      "Epoch 5/99\n",
      "2476/2500 [============================>.] - ETA: 0s - loss: 1.6443 - accuracy: 0.2872\n",
      "Epoch 00005: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6444 - accuracy: 0.2873 - val_loss: 1.6510 - val_accuracy: 0.2907\n",
      "Epoch 6/99\n",
      "2468/2500 [============================>.] - ETA: 0s - loss: 1.6226 - accuracy: 0.2907\n",
      "Epoch 00006: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6225 - accuracy: 0.2908 - val_loss: 1.6068 - val_accuracy: 0.2932\n",
      "Epoch 7/99\n",
      "2473/2500 [============================>.] - ETA: 0s - loss: 1.5957 - accuracy: 0.2999\n",
      "Epoch 00007: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.5957 - accuracy: 0.2995 - val_loss: 1.5891 - val_accuracy: 0.2962\n",
      "Epoch 8/99\n",
      "2494/2500 [============================>.] - ETA: 0s - loss: 1.5827 - accuracy: 0.3035\n",
      "Epoch 00008: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.5824 - accuracy: 0.3035 - val_loss: 1.5855 - val_accuracy: 0.3041\n",
      "Epoch 9/99\n",
      "2493/2500 [============================>.] - ETA: 0s - loss: 1.5688 - accuracy: 0.3072\n",
      "Epoch 00009: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.5686 - accuracy: 0.3074 - val_loss: 1.5740 - val_accuracy: 0.3088\n",
      "Epoch 10/99\n",
      "2472/2500 [============================>.] - ETA: 0s - loss: 1.5460 - accuracy: 0.3187\n",
      "Epoch 00010: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.5459 - accuracy: 0.3190 - val_loss: 1.5497 - val_accuracy: 0.3256\n",
      "Epoch 11/99\n",
      "2490/2500 [============================>.] - ETA: 0s - loss: 1.5207 - accuracy: 0.3352\n",
      "Epoch 00011: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.5204 - accuracy: 0.3352 - val_loss: 1.5210 - val_accuracy: 0.3362\n",
      "Epoch 12/99\n",
      "2483/2500 [============================>.] - ETA: 0s - loss: 1.4846 - accuracy: 0.3473\n",
      "Epoch 00012: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.4846 - accuracy: 0.3474 - val_loss: 1.4853 - val_accuracy: 0.3502\n",
      "Epoch 13/99\n",
      "2490/2500 [============================>.] - ETA: 0s - loss: 1.4562 - accuracy: 0.3541\n",
      "Epoch 00013: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.4562 - accuracy: 0.3540 - val_loss: 1.4590 - val_accuracy: 0.3528\n",
      "Epoch 14/99\n",
      "2490/2500 [============================>.] - ETA: 0s - loss: 1.4218 - accuracy: 0.3652\n",
      "Epoch 00014: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.4218 - accuracy: 0.3650 - val_loss: 1.4147 - val_accuracy: 0.3683\n",
      "Epoch 15/99\n",
      "2487/2500 [============================>.] - ETA: 0s - loss: 1.3951 - accuracy: 0.3725\n",
      "Epoch 00015: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3948 - accuracy: 0.3726 - val_loss: 1.4018 - val_accuracy: 0.3735\n",
      "Epoch 16/99\n",
      "2485/2500 [============================>.] - ETA: 0s - loss: 1.3779 - accuracy: 0.3796\n",
      "Epoch 00016: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3777 - accuracy: 0.3798 - val_loss: 1.3746 - val_accuracy: 0.3769\n",
      "Epoch 17/99\n",
      "2481/2500 [============================>.] - ETA: 0s - loss: 1.3619 - accuracy: 0.3802\n",
      "Epoch 00017: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3614 - accuracy: 0.3803 - val_loss: 1.3660 - val_accuracy: 0.3796\n",
      "Epoch 18/99\n",
      "2488/2500 [============================>.] - ETA: 0s - loss: 1.3542 - accuracy: 0.3824\n",
      "Epoch 00018: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3543 - accuracy: 0.3824 - val_loss: 1.3610 - val_accuracy: 0.3804\n",
      "Epoch 19/99\n",
      "2494/2500 [============================>.] - ETA: 0s - loss: 1.3385 - accuracy: 0.3849 ETA: 0s - loss: 1.3388 - accura\n",
      "Epoch 00019: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.3385 - accuracy: 0.3850 - val_loss: 1.3488 - val_accuracy: 0.3817\n",
      "Epoch 20/99\n",
      "2482/2500 [============================>.] - ETA: 0s - loss: 1.3272 - accuracy: 0.3903\n",
      "Epoch 00020: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.3269 - accuracy: 0.3903 - val_loss: 1.3537 - val_accuracy: 0.3879\n",
      "Epoch 21/99\n",
      "2486/2500 [============================>.] - ETA: 0s - loss: 1.3262 - accuracy: 0.3889\n",
      "Epoch 00021: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.3260 - accuracy: 0.3887 - val_loss: 1.3341 - val_accuracy: 0.3959\n",
      "Epoch 22/99\n",
      "2481/2500 [============================>.] - ETA: 0s - loss: 1.3184 - accuracy: 0.3928\n",
      "Epoch 00022: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.3180 - accuracy: 0.3931 - val_loss: 1.3280 - val_accuracy: 0.3943\n",
      "Epoch 23/99\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 1.3110 - accuracy: 0.3980\n",
      "Epoch 00023: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.3109 - accuracy: 0.3980 - val_loss: 1.3278 - val_accuracy: 0.3953\n",
      "Epoch 24/99\n",
      "2494/2500 [============================>.] - ETA: 0s - loss: 1.3069 - accuracy: 0.3990\n",
      "Epoch 00024: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3068 - accuracy: 0.3990 - val_loss: 1.3394 - val_accuracy: 0.3983\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_81 (Dense)             (None, 320)               251200    \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 150)               48150     \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 100)               15100     \n",
      "=================================================================\n",
      "Total params: 314,450\n",
      "Trainable params: 314,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = create_model()  # Start with same architecture\n",
    "m.load_weights('./weights_best.h5')  # Load instead of train\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3cqpHQt_SIbW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 800us/step - loss: 1.3394 - accuracy: 0.3983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3393654823303223, 0.3982999920845032]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 2.9471 - accuracy: 0.1052\n",
      "Epoch 00001: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 2.9471 - accuracy: 0.1052 - val_loss: 2.3615 - val_accuracy: 0.0975\n",
      "Epoch 2/99\n",
      "2468/2500 [============================>.] - ETA: 0s - loss: 2.3227 - accuracy: 0.1004\n",
      "Epoch 00002: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 2.3225 - accuracy: 0.1004 - val_loss: 2.3070 - val_accuracy: 0.0964\n",
      "Epoch 3/99\n",
      "2479/2500 [============================>.] - ETA: 0s - loss: 2.2392 - accuracy: 0.1540\n",
      "Epoch 00003: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 2.2381 - accuracy: 0.1546 - val_loss: 2.1135 - val_accuracy: 0.1873\n",
      "Epoch 4/99\n",
      "2468/2500 [============================>.] - ETA: 0s - loss: 2.0537 - accuracy: 0.1901\n",
      "Epoch 00004: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 2.0530 - accuracy: 0.1904 - val_loss: 2.0159 - val_accuracy: 0.1855\n",
      "Epoch 5/99\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 1.9952 - accuracy: 0.1934\n",
      "Epoch 00005: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.9952 - accuracy: 0.1934 - val_loss: 1.9909 - val_accuracy: 0.1895\n",
      "Epoch 6/99\n",
      "2479/2500 [============================>.] - ETA: 0s - loss: 1.9561 - accuracy: 0.1983\n",
      "Epoch 00006: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.9561 - accuracy: 0.1982 - val_loss: 1.9402 - val_accuracy: 0.1956\n",
      "Epoch 7/99\n",
      "2494/2500 [============================>.] - ETA: 0s - loss: 1.8673 - accuracy: 0.2545\n",
      "Epoch 00007: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.8670 - accuracy: 0.2548 - val_loss: 1.7771 - val_accuracy: 0.2795\n",
      "Epoch 8/99\n",
      "2494/2500 [============================>.] - ETA: 0s - loss: 1.7004 - accuracy: 0.2821\n",
      "Epoch 00008: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.7003 - accuracy: 0.2821 - val_loss: 1.6570 - val_accuracy: 0.2804\n",
      "Epoch 9/99\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 1.6421 - accuracy: 0.2890\n",
      "Epoch 00009: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6420 - accuracy: 0.2890 - val_loss: 1.6392 - val_accuracy: 0.2882\n",
      "Epoch 10/99\n",
      "2468/2500 [============================>.] - ETA: 0s - loss: 1.6082 - accuracy: 0.2931\n",
      "Epoch 00010: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6084 - accuracy: 0.2928 - val_loss: 1.6086 - val_accuracy: 0.2919\n",
      "Epoch 11/99\n",
      "2494/2500 [============================>.] - ETA: 0s - loss: 1.5956 - accuracy: 0.2931\n",
      "Epoch 00011: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.5955 - accuracy: 0.2932 - val_loss: 1.5923 - val_accuracy: 0.2931\n",
      "Epoch 12/99\n",
      "2467/2500 [============================>.] - ETA: 0s - loss: 1.5831 - accuracy: 0.2994\n",
      "Epoch 00012: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.5830 - accuracy: 0.2997 - val_loss: 1.6056 - val_accuracy: 0.3051\n",
      "Epoch 13/99\n",
      "2467/2500 [============================>.] - ETA: 0s - loss: 1.5640 - accuracy: 0.3005\n",
      "Epoch 00013: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.5643 - accuracy: 0.3004 - val_loss: 1.5683 - val_accuracy: 0.3014\n",
      "Epoch 14/99\n",
      "2488/2500 [============================>.] - ETA: 0s - loss: 1.5547 - accuracy: 0.3086\n",
      "Epoch 00014: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.5545 - accuracy: 0.3087 - val_loss: 1.5533 - val_accuracy: 0.3149\n",
      "Epoch 15/99\n",
      "2491/2500 [============================>.] - ETA: 0s - loss: 1.5325 - accuracy: 0.3277\n",
      "Epoch 00015: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.5324 - accuracy: 0.3278 - val_loss: 1.5383 - val_accuracy: 0.3492\n",
      "Epoch 16/99\n",
      "2483/2500 [============================>.] - ETA: 0s - loss: 1.5001 - accuracy: 0.3558\n",
      "Epoch 00016: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.5006 - accuracy: 0.3558 - val_loss: 1.5202 - val_accuracy: 0.3703\n",
      "Epoch 17/99\n",
      "2485/2500 [============================>.] - ETA: 0s - loss: 1.4583 - accuracy: 0.3826\n",
      "Epoch 00017: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4585 - accuracy: 0.3826 - val_loss: 1.4716 - val_accuracy: 0.3822\n",
      "Epoch 18/99\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 1.4127 - accuracy: 0.4093\n",
      "Epoch 00018: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4125 - accuracy: 0.4095 - val_loss: 1.3738 - val_accuracy: 0.4508\n",
      "Epoch 19/99\n",
      "2477/2500 [============================>.] - ETA: 0s - loss: 1.3275 - accuracy: 0.4604\n",
      "Epoch 00019: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3273 - accuracy: 0.4602 - val_loss: 1.3381 - val_accuracy: 0.4538\n",
      "Epoch 20/99\n",
      "2485/2500 [============================>.] - ETA: 0s - loss: 1.2740 - accuracy: 0.4751\n",
      "Epoch 00020: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2745 - accuracy: 0.4748 - val_loss: 1.3088 - val_accuracy: 0.4694\n",
      "Epoch 21/99\n",
      "2485/2500 [============================>.] - ETA: 0s - loss: 1.2465 - accuracy: 0.4841\n",
      "Epoch 00021: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2468 - accuracy: 0.4841 - val_loss: 1.2777 - val_accuracy: 0.4679\n",
      "Epoch 22/99\n",
      "2480/2500 [============================>.] - ETA: 0s - loss: 1.2249 - accuracy: 0.4871\n",
      "Epoch 00022: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.2253 - accuracy: 0.4872 - val_loss: 1.2500 - val_accuracy: 0.4700\n",
      "Epoch 23/99\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 1.1971 - accuracy: 0.5221\n",
      "Epoch 00023: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1971 - accuracy: 0.5222 - val_loss: 1.1891 - val_accuracy: 0.5493\n",
      "Epoch 24/99\n",
      "2474/2500 [============================>.] - ETA: 0s - loss: 1.1239 - accuracy: 0.5618\n",
      "Epoch 00024: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1229 - accuracy: 0.5619 - val_loss: 1.1287 - val_accuracy: 0.5583\n",
      "Epoch 25/99\n",
      "2491/2500 [============================>.] - ETA: 0s - loss: 1.0881 - accuracy: 0.5693\n",
      "Epoch 00025: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0883 - accuracy: 0.5693 - val_loss: 1.1187 - val_accuracy: 0.5594\n",
      "Epoch 26/99\n",
      "2476/2500 [============================>.] - ETA: 0s - loss: 1.0699 - accuracy: 0.5788\n",
      "Epoch 00026: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0697 - accuracy: 0.5788 - val_loss: 1.0693 - val_accuracy: 0.5860\n",
      "Epoch 27/99\n",
      "2476/2500 [============================>.] - ETA: 0s - loss: 1.0227 - accuracy: 0.6013\n",
      "Epoch 00027: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0223 - accuracy: 0.6015 - val_loss: 1.0509 - val_accuracy: 0.5958\n",
      "Epoch 28/99\n",
      "2477/2500 [============================>.] - ETA: 0s - loss: 0.9945 - accuracy: 0.6097\n",
      "Epoch 00028: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9945 - accuracy: 0.6097 - val_loss: 1.0125 - val_accuracy: 0.6079\n",
      "Epoch 29/99\n",
      "2484/2500 [============================>.] - ETA: 0s - loss: 0.9785 - accuracy: 0.6133\n",
      "Epoch 00029: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9784 - accuracy: 0.6133 - val_loss: 1.0020 - val_accuracy: 0.6058\n",
      "Epoch 30/99\n",
      "2487/2500 [============================>.] - ETA: 0s - loss: 0.9585 - accuracy: 0.6176\n",
      "Epoch 00030: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9583 - accuracy: 0.6178 - val_loss: 0.9900 - val_accuracy: 0.6119\n",
      "Epoch 31/99\n",
      "2490/2500 [============================>.] - ETA: 0s - loss: 0.9408 - accuracy: 0.6246 ETA: 0s - loss: 0\n",
      "Epoch 00031: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9406 - accuracy: 0.6246 - val_loss: 0.9808 - val_accuracy: 0.6143\n",
      "Epoch 32/99\n",
      "2472/2500 [============================>.] - ETA: 0s - loss: 0.9265 - accuracy: 0.6270\n",
      "Epoch 00032: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9270 - accuracy: 0.6267 - val_loss: 0.9731 - val_accuracy: 0.6165\n",
      "Epoch 33/99\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 0.9209 - accuracy: 0.6283\n",
      "Epoch 00033: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9207 - accuracy: 0.6284 - val_loss: 0.9536 - val_accuracy: 0.6205\n",
      "Epoch 34/99\n",
      "2489/2500 [============================>.] - ETA: 0s - loss: 0.9112 - accuracy: 0.6312\n",
      "Epoch 00034: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9110 - accuracy: 0.6313 - val_loss: 0.9456 - val_accuracy: 0.6288\n",
      "Epoch 35/99\n",
      "2477/2500 [============================>.] - ETA: 0s - loss: 0.9053 - accuracy: 0.6323\n",
      "Epoch 00035: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9051 - accuracy: 0.6321 - val_loss: 0.9469 - val_accuracy: 0.6177\n",
      "Epoch 36/99\n",
      "2493/2500 [============================>.] - ETA: 0s - loss: 0.8930 - accuracy: 0.6339\n",
      "Epoch 00036: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8929 - accuracy: 0.6339 - val_loss: 0.9374 - val_accuracy: 0.6266\n",
      "Epoch 37/99\n",
      "2481/2500 [============================>.] - ETA: 0s - loss: 0.8908 - accuracy: 0.6340\n",
      "Epoch 00037: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8905 - accuracy: 0.6341 - val_loss: 0.9425 - val_accuracy: 0.6226\n",
      "Epoch 38/99\n",
      "2487/2500 [============================>.] - ETA: 0s - loss: 0.8827 - accuracy: 0.6359\n",
      "Epoch 00038: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8828 - accuracy: 0.6357 - val_loss: 0.9457 - val_accuracy: 0.6195\n",
      "Epoch 39/99\n",
      "2484/2500 [============================>.] - ETA: 0s - loss: 0.8769 - accuracy: 0.6355\n",
      "Epoch 00039: saving model to weights_best.h5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8770 - accuracy: 0.6356 - val_loss: 0.9511 - val_accuracy: 0.6170\n",
      "Epoch 1/5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8700 - accuracy: 0.6406\n",
      "Epoch 2/5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8672 - accuracy: 0.6399\n",
      "Epoch 3/5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8572 - accuracy: 0.6449\n",
      "Epoch 4/5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8592 - accuracy: 0.6449\n",
      "Epoch 5/5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8535 - accuracy: 0.6467\n",
      "WARNING:tensorflow:From /Users/johnrivera/.virtualenvs/DS-Unit-4-Sprint-2-Neural-Networks-Hdtrba5g/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Users/johnrivera/.virtualenvs/DS-Unit-4-Sprint-2-Neural-Networks-Hdtrba5g/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save entire model\n",
    "# i.e. both weights and architecture\n",
    "# Create and train a new model instance.\n",
    "model = create_model()\n",
    "model.fit(X_train, y_train, epochs=5)\n",
    "\n",
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_84 (Dense)             (None, 320)               251200    \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 150)               48150     \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 100)               15100     \n",
      "=================================================================\n",
      "Total params: 314,450\n",
      "Trainable params: 314,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load it back fresh, including weights and architecture\n",
    "new_model = tf.keras.models.load_model('saved_model/my_model')\n",
    "# Recompiling the model tells it how to calculate accuracy correctly :)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the \"full model\" does save the architecture and weights\n",
    "# but not the compile details (since those aren't really needed for inference)\n",
    "new_model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 854us/step - loss: 0.9319 - accuracy: 0.6334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.931868851184845, 0.633400022983551]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 54152\n",
      "drwxr-xr-x@ 11 johnrivera  staff   352B Sep 10 16:27 \u001b[34m.\u001b[m\u001b[m\n",
      "drwxr-xr-x@ 15 johnrivera  staff   480B Sep 10 16:26 \u001b[34m..\u001b[m\u001b[m\n",
      "drwxr-xr-x@  5 johnrivera  staff   160B Sep 10 15:25 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m\n",
      "-rw-r--r--   1 johnrivera  staff    49K Sep 10 14:08 9_10_2020.ipynb\n",
      "-rw-r--r--@  1 johnrivera  staff    51K Sep 10 16:25 9_10_v2.ipynb\n",
      "-rw-r--r--   1 johnrivera  staff    67K Sep 10 16:27 LS_DS_434_Deploy_Assignment.ipynb\n",
      "drwxr-xr-x@  4 johnrivera  staff   128B Sep 10 13:02 \u001b[34mPast_Lect\u001b[m\u001b[m\n",
      "drwxr-xr-x@  5 johnrivera  staff   160B Sep 10 16:14 \u001b[34mlogs\u001b[m\u001b[m\n",
      "-rw-r--r--   1 johnrivera  staff    24M Sep  6 18:52 quickdraw10.npz\n",
      "drwxr-xr-x@  3 johnrivera  staff    96B Sep 10 16:25 \u001b[34msaved_model\u001b[m\u001b[m\n",
      "-rw-r--r--   1 johnrivera  staff   1.2M Sep 10 16:22 weights_best.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -alh  # checking memory of model, 96B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LKbr1gRg9BXs"
   },
   "source": [
    "### Stretch Goals\n",
    "- Mount your Google Drive to Colab to persist your model checkpoint files. \n",
    "- Research L2 normalization (weight decay)\n",
    "- Write a custom callback function to stop training after you reach .88 validation accuracy. \n",
    "- Select a new dataset and apply a neural network to it.\n",
    "- Research TensorFlow Serving\n",
    "- Play [QuickDraw](https://quickdraw.withgoogle.com/data)\n",
    "- Create a static webpage using TensorFlow.js to serve a model. Check out [Teachable Machine Learning](https://teachablemachine.withgoogle.com/) for ideas. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_434_Deploy_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
